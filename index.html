<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta property="og:title" content="DIFA: Deep Learning-based Image Fusion and Its Applications"/>
  <meta property="og:url" content="https://difa2024.github.io"/>
  <!-- <meta property="og:image" content="static/figures/teaser.jpg" /> -->
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <title>DIFA</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link rel="icon" href="static/figures/elephant.jpeg">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <style>
    .author-block {
        margin-right: 20px; /* Adjust this value to increase or decrease the spacing */
    }

    .school-block {
            margin-right: 20px; /* Adjust this value to increase or decrease the spacing for schools */
    }

    .content ul {
        list-style-type: none; /* Optional: Remove bullet points if desired */
        padding-left: 0; /* Optional: Adjust padding */
    }

    .content li {
        margin-bottom: 10px; /* Optional: Add space between list items */
    }

    /* To ensure that lines are not too short */
    .content.has-text-justified {
      max-width: 1200px; /* Adjust the maximum width as needed */
      margin: 0 auto; /* Center the content */
    }

    section {
      font-size: 1.5rem; /* Adjust the font size as needed */
    }

</style>

</head>
<body>


<section class="publication-header">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <!-- <div class="columns is-centered"> -->
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">BMVC2024 Workshop</h1>
          <h1 class="title is-2 publication-title">DIFA: Deep Learning-based Image Fusion and Its Applications</h1>
          <h1 class="title is-4 publication-title">27th or 28th November, 2024, Glasgow, UK</h1>
        </div>
    </div>
  </div>   
</section>

<section class="publication-author-block">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
		<div class="is-size-4 publication-authors">
      <span class="author-block"><a href="https://computerscience.exeter.ac.uk/people/profile/index.php?web_id=xz569" target="_blank">Xingchen Zhang</a><sup>1</sup></span>
			<span class="author-block"><a href="https://www.sheffield.ac.uk/cs/people/academic/zhixiang-chen" target="_blank">Zhixiang Chen</a><sup>2</sup></span>
			<span class="author-block"><a href="https://pure.qub.ac.uk/en/persons/shuyan-li" target="_blank">Shuyan Li</a><sup>3</sup></span>
			<span class="author-block"><a href="https://profiles.imperial.ac.uk/y.demiris" target="_blank">Yiannis Demiris</a><sup>4</sup></span>
          </div>
	  <div class="is-size-6 publication-authors">
      <span class="school-block"><sup>1</sup>University of Exeter</span>
      <span class="school-block"><sup>2</sup>University of Sheffield</span>
      <span class="school-block"><sup>3</sup>Queen's University Belfast</span>
      <span class="school-block"><sup>4</sup>Imperial College London</span>
    </div>
	  
	  <!-- <div class="is-size-3 publication-authors">
            <span class="author-block"><a href="https://fusion2024.org/tutorials/#l10" target="_blank">FUSION 2024 Tutorial</a></span> 
    </div> -->

	<!-- <div class="is-size-4 publication-authors"> -->
        <!--     <span class="author-block">Monday, July 8th Afternoon</span>  -->
        <!--   </div> -->

	<!-- <div class="is-size-4 publication-authors"> -->
        <!--     <span class="title is-5 blink"> <a href="https://fusion2024.org/register/">Register</a> </span>  -->
        <!--   </div> -->
 

        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-widescreen">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
	    Deep learning-based image fusion has garnered considerable attention in recent years. However, despite massive progress, some challenges remain. Notably, there have not been any workshops dedicated to image fusion. This workshop will provide an introduction to deep learning-based image fusion and its applications, covering both methods and typical applications. It will also delve into other pertinent challenges, such as the need for comprehensive image fusion benchmarks. Hosting this workshop now offers a timely opportunity to summarize the development of image fusion and introduce image fusion to more researchers. Additionally, this workshop presents an opportunity for students and researchers in other fields to discover how they can benefit from image fusion technologies.

          </p>
          </p>
Image fusion has been a subject of study for over 30 years. The field experienced a significant milestone in around 2017 with the introduction of deep learning techniques. Since then, deep learning-based image fusion has attracted significant attention, leading to substantial progress in algorithms, datasets, and benchmarks. Furthermore, image fusion has demonstrated its utility across a wide range of applications, including object tracking, object detection, medical image processing, robotics, autonomous driving, scene segmentation, pedestrian and cyclist detection, salient object detection, power facility inspection, surveillance, face recognition, crowd counting, vital sign measurement, motion estimation, crack detection in civil infrastructure, and multi-physiological signal estimation.

          </p>
          </p>
The workshop will introduce the latest advancements in deep learning-based image fusion and discuss its wide range of applications. This workshop will offer a space for image fusion researchers to know both the advancements and challenges, and for the broad community in computer vision and robotics to discover how their applications can benefit from the development of image fusion. To the best of our knowledge, this will be the first workshop to specifically focus on the intricacies of image fusion, highlighting the unique value of our DIFA workshop in the context of related events. Particularly at a time when the field of image fusion is evolving rapidly, this workshop will be invaluable in providing a forum to summarize past developments, delve into current trends, and anticipate the future directions of this dynamic field.

          </p>
        </div>
</section>

<section class="section hero">
  <div class="container is-widescreen">
    <!-- <div class="columns is-left"> -->
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-3 has-text-centered">Call for papers</h2>
		
		<div class="content has-text-justified">
          <p>
			 The workshop will cover (but is not limited to) the following topics. 

		  <h5 class="title is-5">Different image fusion tasks</h5>
		  
		  <ul>
		    <li>
		      Visible and infrared image fusion
		    </li>
		    <li>
		      Multi-focus image fusion
		    </li>
		    <li>
		      Multi-exposure image fusion
		    </li>
		    <li>
		      Medical image fusion
		    </li>
		    <li>
		      Remote sensing image fusion
		    </li>
		    <li>
		      Multimodal image fusion
		    </li>
		    <li>
		      General image fusion
		    </li>
		    <li>
		      Other types of image fusion
		    </li>
		  </ul>

		  
		  <h5 class="title is-5">Deep learning methods for image fusion</h5>
		  
		  <ul>
		    <li>
		      CNN-based methods
		    </li>
		    <li>
		      GAN-based methods
		    </li>
		    <li>
		      Autoencoder-based methods
		    </li>
		    <li>
		      Transformer-based methods
		    </li>
		    <li>
		      Diffusion model-based methods
		    </li>
		    <li>
		      Application-driven image fusion methods
		    </li>
		    <li>
		      Image registration methods for image fusion
		    </li>

		  </ul>

		  <h5 class="title is-5">Dataset and performance evaluation</h5>
		  
		  <ul>
		    <li>
		      Image fusion datasets
		    </li>
		    <li>
		      Image fusion evaluation metrics
		    </li>
		    <li>
		      Image fusion evaluation methods
		    </li>
		    <li>
		      Image fusion benchmarks
		    </li>
		  </ul>

		  
		  <h5 class="title is-5">Image fusion applications</h5>    		  
		  <ul>
		    <li>
		      Low-level vision tasks
		    </li>
		    <li>
		      Object tracking
		    </li>
		    <li>
		      Object detection
		    </li>
		    <li>
		      Scene segmentation
		    </li>
		    <li>
		      Robotics
		    </li>
		    <li>
		      Others
		    </li>
		  </ul>

		  </p>
		  
		  
        </div>

     
  <h2 class="title is-3 has-text-centered">Important dates</h2>
  <div class="content has-text-justified">
    <p>
      <ul>
        <li>Submission deadline: July 26th 2024, 23:59 (UK time)</li>
        <li>Notification of acceptance: August 16th, 2024</li>
        <li>Camera-ready submission: September 16th, 2024</li>
      </ul>
    </p>
  </div>   

  <h2 class="title is-3 has-text-centered">Paper submission</h2>
  <div class="content has-text-justified">
    <p>
      <ul>
        <li> Papers can be submitted via OpenReview. Format must follow the requirement of BMVC2024 main conference.</li>
      </ul>
    </p>
  </div>   

        <h2 class="title is-3 has-text-centered">Tentative Program</h2>
        <div class="content has-text-justified">
          <p>
		  <ul>
		    <li>
	    08:00 - 08:15 Opening Remarks 
		    </li>
		    <li>
		      08:15 - 09:00 Keynote: Invited Speaker 1
		    </li>
		    <li>
		      09:00 - 09:45 Keynote: Invited Speaker 2
		    </li>
		    <li>
		      09:45 - 10:00 Break 
		    </li>
		    <li>
		      10:00 - 10:15 Contributed talk 1 
		    </li>
		    <li>
		      10:15 - 10:30 Contributed talk 2
		    </li>
		    <li>
		      10:30 - 10:45 Contributed talk 3
		    </li>
		    <li>
		      10:45 - 11:00 Contributed talk 4 
		    </li>
		    <li>
		      11:00 - 11:15 Contributed talk 5 
		    </li>
		    <li>
		      11:15 - 11:50 Break and post section (4 posters) 
		    </li>
		    <li>
		      11:50 - 11:55 Best paper award announcement 
		    </li>
		    <li>
		      11:55 - 12:00 Closing Remarks
		    </li>
		    </ul>
      
	</p>
	</div>


		
        <!-- <h2 class="title is-3 has-text-centered">Intended Audience</h2> -->
        <!-- <div class="content has-text-justified"> -->
        <!--   <p> -->
	<!--     We cordially invite students and researchers from the fields of image fusion, image registration, and computer vision to attend the tutorial and delve into recent advancements and challenges in image fusion. Additionally, students and researchers from other domains who have an interest in the application of image fusion are also encouraged to participate. This tutorial represents a unique opportunity to engage with the latest developments in the field and to network with peers who share a common interest in the potential of image fusion technologies. -->
      
	<!-- </p> -->
	<!-- </div> -->

        <!-- <h2 class="title is-3 has-text-centered">Tutorial Logistics</h2> -->
        <!-- <div class="content has-text-justified"> -->
        <!-- <p> -->
	<!-- 		  Our tutorial will be conducted in a hybrid manner on June 18, 2022 from 9 AM onwards. We aim to complete our tutorial by 12:00 PM (Canada time). Due the VISA issues, Sayak won't be able to present in person. So, he will be joining and presenting virtually. Our guest speaker Ron will also be presenting virtually. However, Hila will be presenting in person. -->
        <!-- <ul> -->
        <!--   <li><b>For in-person attendees: </b>Our tutorial will be presented at the Vancouver Convention Center <b>West 211</b>.</li> -->
        <!--   <li><b>For virtual attendees: </b>Please see the <a href="https://cvpr2023.thecvf.com/virtual/current/index.html">virtual site</a>, where you can find the homepage of <a href="https://cvpr2023.thecvf.com/virtual/2023/tutorial/18574">our tutorial</a>. All the (registered) participants (both in-person and virtual) of CVPR will have access to a Zoom link to join the tutorial live and ask questions to the speakers via RocketChat.</li> -->
        <!-- </ul> -->
      
	<!-- </p> -->
	<!-- </div> -->

		
		<p class="content">
      </div>
    </div>
  </div>
</section> 

<footer class="footer">
  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">
        <p>
          This website is licensed under a <a rel="license"
          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
        Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
      <p>
        Website source code based on the <a href="https://all-things-vits.github.io/atv//"> All Things ViTs</a> tutorial page. If you want to reuse their <a
        href="https://github.com/all-things-vits/atv">source code</a>, please credit them appropriately.
      </p>
    </div>
  </div>
</div>
</div>
</footer>


  <script type="text/javascript">
    var sc_project=12351448; 
    var sc_invisible=1; 
    var sc_security="c676de4f"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js"
  async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
    href="https://statcounter.com/" target="_blank"><img
    class="statcounter"
    src="https://c.statcounter.com/12351448/0/c676de4f/1/"
    alt="Web Analytics"></a></div></noscript>
    <!-- End of Statcounter Code -->

  </body>
  </html>
